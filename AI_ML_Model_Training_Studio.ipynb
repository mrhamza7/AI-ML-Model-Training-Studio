{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio"
      ],
      "metadata": {
        "id": "16KhgGNeZkl5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit pandas scikit-learn seaborn matplotlib gradio",
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "metadata": {
        "id": "nW-J-TjaZXxP"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set style for matplotlib\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Global variables to store data and model\n",
        "dataset = None\n",
        "trained_model = None\n",
        "X_train, X_test, y_train, y_test = None, None, None, None\n",
        "scaler = StandardScaler()\n",
        "label_encoders = {}"
      ],
      "metadata": {
        "id": "TVT-qbaEZxR-"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(file):\n",
        "    \"\"\"Load and preview dataset\"\"\"\n",
        "    global dataset\n",
        "    try:\n",
        "        if file.name.endswith('.csv'):\n",
        "            dataset = pd.read_csv(file.name)\n",
        "        elif file.name.endswith(('.xlsx', '.xls')):\n",
        "            dataset = pd.read_excel(file.name)\n",
        "        else:\n",
        "            return \"‚ùå Please upload a CSV or Excel file\", None, [], []\n",
        "\n",
        "        # Get column names for dropdowns\n",
        "        columns = dataset.columns.tolist()\n",
        "\n",
        "        # Create a beautiful preview\n",
        "        preview_html = f\"\"\"\n",
        "        <div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 20px; border-radius: 10px; color: white; margin: 10px 0;\">\n",
        "            <h3>üìä Dataset Loaded Successfully!</h3>\n",
        "            <p><strong>Shape:</strong> {dataset.shape[0]} rows √ó {dataset.shape[1]} columns</p>\n",
        "            <p><strong>Size:</strong> {dataset.memory_usage(deep=True).sum() / 1024:.2f} KB</p>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "        return preview_html, dataset.head(10), columns, columns\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Error loading file: {str(e)}\", None, [], []"
      ],
      "metadata": {
        "id": "MKomuMQQZ2LE"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset_info():\n",
        "    \"\"\"Get detailed dataset information\"\"\"\n",
        "    if dataset is None:\n",
        "        return \"‚ö†Ô∏è Please upload a dataset first\"\n",
        "\n",
        "    info_html = f\"\"\"\n",
        "    <div style=\"background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%); padding: 20px; border-radius: 10px; color: white;\">\n",
        "        <h3>üìà Dataset Information</h3>\n",
        "        <div style=\"display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 15px; margin-top: 15px;\">\n",
        "            <div style=\"background: rgba(255,255,255,0.2); padding: 15px; border-radius: 8px;\">\n",
        "                <h4>üìä Basic Stats</h4>\n",
        "                <p><strong>Rows:</strong> {dataset.shape[0]}</p>\n",
        "                <p><strong>Columns:</strong> {dataset.shape[1]}</p>\n",
        "                <p><strong>Memory:</strong> {dataset.memory_usage(deep=True).sum() / 1024:.2f} KB</p>\n",
        "            </div>\n",
        "            <div style=\"background: rgba(255,255,255,0.2); padding: 15px; border-radius: 8px;\">\n",
        "                <h4>üîç Data Types</h4>\n",
        "                <p><strong>Numeric:</strong> {dataset.select_dtypes(include=[np.number]).shape[1]}</p>\n",
        "                <p><strong>Categorical:</strong> {dataset.select_dtypes(include=['object']).shape[1]}</p>\n",
        "                <p><strong>Missing Values:</strong> {dataset.isnull().sum().sum()}</p>\n",
        "            </div>\n",
        "        </div>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "    return info_html"
      ],
      "metadata": {
        "id": "8hon45HQZ6lI"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(features, target, model_name, test_size):\n",
        "    \"\"\"Train the selected model\"\"\"\n",
        "    global trained_model, X_train, X_test, y_train, y_test, scaler, label_encoders\n",
        "\n",
        "    if dataset is None:\n",
        "        return \"‚ö†Ô∏è Please upload a dataset first\", None\n",
        "\n",
        "    if not features or not target:\n",
        "        return \"‚ö†Ô∏è Please select features and target\", None\n",
        "\n",
        "    try:\n",
        "        # Prepare data\n",
        "        X = dataset[features].copy()\n",
        "        y = dataset[target].copy()\n",
        "\n",
        "        # Handle categorical variables\n",
        "        for col in X.columns:\n",
        "            if X[col].dtype == 'object':\n",
        "                le = LabelEncoder()\n",
        "                X[col] = le.fit_transform(X[col].astype(str))\n",
        "                label_encoders[col] = le\n",
        "\n",
        "        # Handle target variable\n",
        "        if y.dtype == 'object':\n",
        "            le_target = LabelEncoder()\n",
        "            y = le_target.fit_transform(y.astype(str))\n",
        "            label_encoders['target'] = le_target\n",
        "            task_type = 'classification'\n",
        "        else:\n",
        "            task_type = 'regression' if len(y.unique()) > 10 else 'classification'\n",
        "\n",
        "        # Split data\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=test_size/100, random_state=42, stratify=y if task_type == 'classification' else None\n",
        "        )\n",
        "\n",
        "        # Scale features\n",
        "        X_train_scaled = scaler.fit_transform(X_train)\n",
        "        X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "        # Model selection\n",
        "        models = {\n",
        "            'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42) if task_type == 'classification' else RandomForestRegressor(n_estimators=100, random_state=42),\n",
        "            'Logistic Regression': LogisticRegression(random_state=42) if task_type == 'classification' else LinearRegression(),\n",
        "            'SVM': SVC(random_state=42) if task_type == 'classification' else None,\n",
        "            'Decision Tree': DecisionTreeClassifier(random_state=42) if task_type == 'classification' else None,\n",
        "            'K-Nearest Neighbors': KNeighborsClassifier() if task_type == 'classification' else None,\n",
        "            'Naive Bayes': GaussianNB() if task_type == 'classification' else None,\n",
        "            'Gradient Boosting': GradientBoostingClassifier(random_state=42) if task_type == 'classification' else None,\n",
        "        }\n",
        "\n",
        "        if model_name not in models or models[model_name] is None:\n",
        "            return f\"‚ö†Ô∏è {model_name} not available for {task_type}\", None\n",
        "\n",
        "        trained_model = models[model_name]\n",
        "\n",
        "        # Train model\n",
        "        if model_name in ['SVM', 'Logistic Regression', 'K-Nearest Neighbors', 'Naive Bayes']:\n",
        "            trained_model.fit(X_train_scaled, y_train)\n",
        "            y_pred = trained_model.predict(X_test_scaled)\n",
        "        else:\n",
        "            trained_model.fit(X_train, y_train)\n",
        "            y_pred = trained_model.predict(X_test)\n",
        "\n",
        "        # Calculate metrics\n",
        "        if task_type == 'classification':\n",
        "            accuracy = accuracy_score(y_test, y_pred)\n",
        "            result_html = f\"\"\"\n",
        "            <div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 20px; border-radius: 10px; color: white;\">\n",
        "                <h3>üéØ Model Training Complete!</h3>\n",
        "                <div style=\"background: rgba(255,255,255,0.2); padding: 15px; border-radius: 8px; margin-top: 15px;\">\n",
        "                    <h4>üìä Results</h4>\n",
        "                    <p><strong>Model:</strong> {model_name}</p>\n",
        "                    <p><strong>Accuracy:</strong> {accuracy:.4f} ({accuracy*100:.2f}%)</p>\n",
        "                    <p><strong>Task Type:</strong> {task_type.title()}</p>\n",
        "                    <p><strong>Features Used:</strong> {len(features)}</p>\n",
        "                    <p><strong>Training Samples:</strong> {len(X_train)}</p>\n",
        "                    <p><strong>Test Samples:</strong> {len(X_test)}</p>\n",
        "                </div>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "        else:\n",
        "            mse = mean_squared_error(y_test, y_pred)\n",
        "            r2 = r2_score(y_test, y_pred)\n",
        "            result_html = f\"\"\"\n",
        "            <div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 20px; border-radius: 10px; color: white;\">\n",
        "                <h3>üéØ Model Training Complete!</h3>\n",
        "                <div style=\"background: rgba(255,255,255,0.2); padding: 15px; border-radius: 8px; margin-top: 15px;\">\n",
        "                    <h4>üìä Results</h4>\n",
        "                    <p><strong>Model:</strong> {model_name}</p>\n",
        "                    <p><strong>R¬≤ Score:</strong> {r2:.4f}</p>\n",
        "                    <p><strong>MSE:</strong> {mse:.4f}</p>\n",
        "                    <p><strong>RMSE:</strong> {np.sqrt(mse):.4f}</p>\n",
        "                    <p><strong>Task Type:</strong> {task_type.title()}</p>\n",
        "                    <p><strong>Features Used:</strong> {len(features)}</p>\n",
        "                </div>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "\n",
        "        return result_html, f\"‚úÖ Model trained successfully with {accuracy*100:.2f}% accuracy!\" if task_type == 'classification' else f\"‚úÖ Model trained successfully with R¬≤ = {r2:.4f}!\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Error training model: {str(e)}\", None"
      ],
      "metadata": {
        "id": "2ExQQvRaaal2"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_confusion_matrix():\n",
        "    \"\"\"Create confusion matrix visualization\"\"\"\n",
        "    if trained_model is None or X_test is None:\n",
        "        return \"‚ö†Ô∏è Please train a model first\"\n",
        "\n",
        "    try:\n",
        "        # Get predictions\n",
        "        if hasattr(trained_model, 'predict'):\n",
        "            if trained_model.__class__.__name__ in ['SVC', 'LogisticRegression', 'KNeighborsClassifier', 'GaussianNB']:\n",
        "                y_pred = trained_model.predict(scaler.transform(X_test))\n",
        "            else:\n",
        "                y_pred = trained_model.predict(X_test)\n",
        "        else:\n",
        "            return \"‚ö†Ô∏è Model doesn't support prediction\"\n",
        "\n",
        "        # Create confusion matrix\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "        # Create beautiful heatmap\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                   square=True, linewidths=0.5, cbar_kws={\"shrink\": .8})\n",
        "        plt.title('üéØ Confusion Matrix', fontsize=16, fontweight='bold', pad=20)\n",
        "        plt.xlabel('Predicted Labels', fontsize=12, fontweight='bold')\n",
        "        plt.ylabel('True Labels', fontsize=12, fontweight='bold')\n",
        "\n",
        "        # Add gradient background\n",
        "        plt.gca().set_facecolor('#f8f9fa')\n",
        "        plt.tight_layout()\n",
        "\n",
        "        return plt\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating confusion matrix: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def create_feature_importance():\n",
        "    \"\"\"Create feature importance visualization\"\"\"\n",
        "    if trained_model is None:\n",
        "        return \"‚ö†Ô∏è Please train a model first\"\n",
        "\n",
        "    try:\n",
        "        if hasattr(trained_model, 'feature_importances_'):\n",
        "            importances = trained_model.feature_importances_\n",
        "            feature_names = X_train.columns\n",
        "\n",
        "            # Create beautiful bar plot\n",
        "            plt.figure(figsize=(12, 8))\n",
        "            indices = np.argsort(importances)[::-1]\n",
        "\n",
        "            colors = plt.cm.viridis(np.linspace(0, 1, len(importances)))\n",
        "            bars = plt.bar(range(len(importances)), importances[indices], color=colors)\n",
        "\n",
        "            plt.title('üîç Feature Importance', fontsize=16, fontweight='bold', pad=20)\n",
        "            plt.xlabel('Features', fontweight='bold')\n",
        "            plt.ylabel('Importance', fontweight='bold')\n",
        "            plt.xticks(range(len(importances)), [feature_names[i] for i in indices], rotation=45, ha='right', fontsize=10)\n",
        "\n",
        "            # Add value labels on bars\n",
        "            for i, bar in enumerate(bars):\n",
        "                plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,\n",
        "                        f'{importances[indices[i]]:.3f}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            return plt\n",
        "        else:\n",
        "            return \"‚ö†Ô∏è This model doesn't provide feature importance\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating feature importance plot: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def create_model_performance():\n",
        "    \"\"\"Create model performance visualization\"\"\"\n",
        "    if trained_model is None or X_test is None:\n",
        "        return \"‚ö†Ô∏è Please train a model first\"\n",
        "\n",
        "    try:\n",
        "        # Get predictions\n",
        "        if trained_model.__class__.__name__ in ['SVC', 'LogisticRegression', 'KNeighborsClassifier', 'GaussianNB']:\n",
        "            y_pred = trained_model.predict(scaler.transform(X_test))\n",
        "        else:\n",
        "            y_pred = trained_model.predict(X_test)\n",
        "\n",
        "        # Create subplots\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "        fig.suptitle('üìä Model Performance Dashboard', fontsize=16, fontweight='bold')\n",
        "\n",
        "        # 1. Prediction vs Actual\n",
        "        axes[0, 0].scatter(y_test, y_pred, alpha=0.6, color='royalblue', edgecolors='white', linewidth=0.5)\n",
        "        axes[0, 0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
        "        axes[0, 0].set_xlabel('Actual Values', fontweight='bold')\n",
        "        axes[0, 0].set_ylabel('Predicted Values', fontweight='bold')\n",
        "        axes[0, 0].set_title('üéØ Predictions vs Actual', fontweight='bold')\n",
        "        axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "        # 2. Residuals\n",
        "        residuals = y_test - y_pred\n",
        "        axes[0, 1].scatter(y_pred, residuals, alpha=0.6, color='green', edgecolors='white', linewidth=0.5)\n",
        "        axes[0, 1].axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
        "        axes[0, 1].set_xlabel('Predicted Values', fontweight='bold')\n",
        "        axes[0, 1].set_ylabel('Residuals', fontweight='bold')\n",
        "        axes[0, 1].set_title('üìà Residual Plot', fontweight='bold')\n",
        "        axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "        # 3. Distribution of residuals\n",
        "        axes[1, 0].hist(residuals, bins=30, alpha=0.7, color='purple', edgecolor='white', linewidth=0.5)\n",
        "        axes[1, 0].set_xlabel('Residuals', fontweight='bold')\n",
        "        axes[1, 0].set_ylabel('Frequency', fontweight='bold')\n",
        "        axes[1, 0].set_title('üìä Residual Distribution', fontweight='bold')\n",
        "        axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "        # 4. Q-Q plot\n",
        "        from scipy import stats\n",
        "        stats.probplot(residuals, dist=\"norm\", plot=axes[1, 1])\n",
        "        axes[1, 1].set_title('üìâ Q-Q Plot', fontweight='bold')\n",
        "        axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        return fig\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating performance plots: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def create_data_distribution():\n",
        "    \"\"\"Create data distribution visualization\"\"\"\n",
        "    if dataset is None:\n",
        "        return \"‚ö†Ô∏è Please upload a dataset first\"\n",
        "\n",
        "    try:\n",
        "        # Get numeric columns\n",
        "        numeric_cols = dataset.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "        if len(numeric_cols) == 0:\n",
        "            return \"‚ö†Ô∏è No numeric columns found for distribution plot\"\n",
        "\n",
        "        # Create subplots\n",
        "        n_cols = min(3, len(numeric_cols))\n",
        "        n_rows = (len(numeric_cols) + n_cols - 1) // n_cols\n",
        "\n",
        "        fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5*n_rows))\n",
        "        fig.suptitle('üìä Data Distribution Dashboard', fontsize=16, fontweight='bold')\n",
        "\n",
        "        if n_rows == 1:\n",
        "            axes = [axes] if n_cols == 1 else axes\n",
        "        else:\n",
        "            axes = axes.flatten()\n",
        "\n",
        "        for i, col in enumerate(numeric_cols):\n",
        "            if i < len(axes):\n",
        "                # Create histogram with KDE\n",
        "                axes[i].hist(dataset[col].dropna(), bins=30, alpha=0.7, color='skyblue', edgecolor='white', density=True)\n",
        "\n",
        "                # Add KDE curve\n",
        "                from scipy.stats import gaussian_kde\n",
        "                data = dataset[col].dropna()\n",
        "                if len(data) > 1:\n",
        "                    kde = gaussian_kde(data)\n",
        "                    x_range = np.linspace(data.min(), data.max(), 100)\n",
        "                    axes[i].plot(x_range, kde(x_range), color='red', linewidth=2, label='KDE')\n",
        "\n",
        "                axes[i].set_xlabel(col, fontweight='bold')\n",
        "                axes[i].set_ylabel('Density', fontweight='bold')\n",
        "                axes[i].set_title(f'üìà {col} Distribution', fontweight='bold')\n",
        "                axes[i].grid(True, alpha=0.3)\n",
        "                axes[i].legend()\n",
        "\n",
        "        # Hide empty subplots\n",
        "        for i in range(len(numeric_cols), len(axes)):\n",
        "            axes[i].set_visible(False)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        return fig\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating distribution plots: {str(e)}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "sKHkUWjKaNsv"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the Gradio interface\n",
        "def create_interface():\n",
        "    with gr.Blocks(theme=gr.themes.Soft(), title=\"ü§ñ AI/ML Model Training Studio\") as demo:\n",
        "        gr.HTML(\"\"\"\n",
        "        <div style=\"text-align: center; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 30px; border-radius: 15px; margin-bottom: 20px;\">\n",
        "            <h1 style=\"color: white; font-size: 2.5em; margin: 0; text-shadow: 2px 2px 4px rgba(0,0,0,0.3);\">\n",
        "                ü§ñ AI/ML Model Training Studio\n",
        "            </h1>\n",
        "            <p style=\"color: white; font-size: 1.2em; margin: 10px 0 0 0; opacity: 0.9;\">\n",
        "                Upload your dataset, select features, train models, and visualize results with beautiful charts!\n",
        "            </p>\n",
        "        </div>\n",
        "        \"\"\")\n",
        "\n",
        "        with gr.Tabs():\n",
        "            # Dataset Upload Tab\n",
        "            with gr.TabItem(\"üìÅ Dataset Upload\", id=\"upload\"):\n",
        "                with gr.Row():\n",
        "                    with gr.Column(scale=1):\n",
        "                        file_input = gr.File(\n",
        "                            label=\"üìÇ Upload Dataset (CSV/Excel)\",\n",
        "                            file_types=['.csv', '.xlsx', '.xls'],\n",
        "                            height=100\n",
        "                        )\n",
        "                        dataset_info = gr.HTML()\n",
        "\n",
        "                    with gr.Column(scale=2):\n",
        "                        dataset_preview = gr.Dataframe(\n",
        "                            label=\"üìä Dataset Preview\",\n",
        "                            interactive=False\n",
        "                        )\n",
        "\n",
        "                # Hidden components to store column names\n",
        "                features_choices = gr.State([])\n",
        "                target_choices = gr.State([])\n",
        "\n",
        "            # Model Training Tab\n",
        "            with gr.TabItem(\"üéØ Model Training\", id=\"training\"):\n",
        "                with gr.Row():\n",
        "                    with gr.Column(scale=1):\n",
        "                        gr.HTML(\"<h3>üîß Model Configuration</h3>\")\n",
        "\n",
        "                        features_dropdown = gr.Dropdown(\n",
        "                            label=\"üé≤ Select Features\",\n",
        "                            choices=[],\n",
        "                            multiselect=True,\n",
        "                            info=\"Choose input features for training\"\n",
        "                        )\n",
        "\n",
        "                        target_dropdown = gr.Dropdown(\n",
        "                            label=\"üéØ Select Target\",\n",
        "                            choices=[],\n",
        "                            multiselect=False,\n",
        "                            info=\"Choose the target variable to predict\"\n",
        "                        )\n",
        "\n",
        "                        model_dropdown = gr.Dropdown(\n",
        "                            label=\"ü§ñ Select Model\",\n",
        "                            choices=[\n",
        "                                \"Random Forest\",\n",
        "                                \"Logistic Regression\",\n",
        "                                \"SVM\",\n",
        "                                \"Decision Tree\",\n",
        "                                \"K-Nearest Neighbors\",\n",
        "                                \"Naive Bayes\",\n",
        "                                \"Gradient Boosting\"\n",
        "                            ],\n",
        "                            value=\"Random Forest\",\n",
        "                            info=\"Choose the machine learning algorithm\"\n",
        "                        )\n",
        "\n",
        "                        test_size_slider = gr.Slider(\n",
        "                            label=\"üìä Test Size (%)\",\n",
        "                            minimum=10,\n",
        "                            maximum=40,\n",
        "                            value=20,\n",
        "                            step=5,\n",
        "                            info=\"Percentage of data for testing\"\n",
        "                        )\n",
        "\n",
        "                        train_button = gr.Button(\n",
        "                            \"üöÄ Train Model\",\n",
        "                            variant=\"primary\",\n",
        "                            size=\"lg\"\n",
        "                        )\n",
        "\n",
        "                    with gr.Column(scale=2):\n",
        "                        training_output = gr.HTML()\n",
        "                        training_status = gr.Textbox(\n",
        "                            label=\"üìà Training Status\",\n",
        "                            interactive=False\n",
        "                        )\n",
        "\n",
        "            # Visualizations Tab\n",
        "            with gr.TabItem(\"üìä Visualizations\", id=\"viz\"):\n",
        "                with gr.Row():\n",
        "                    confusion_btn = gr.Button(\"üéØ Confusion Matrix\", variant=\"secondary\")\n",
        "                    importance_btn = gr.Button(\"‚≠ê Feature Importance\", variant=\"secondary\")\n",
        "                    performance_btn = gr.Button(\"üìà Model Performance\", variant=\"secondary\")\n",
        "                    distribution_btn = gr.Button(\"üìä Data Distribution\", variant=\"secondary\")\n",
        "\n",
        "                viz_output = gr.Plot(\n",
        "                    label=\"üìä Visualization Output\"\n",
        "                )\n",
        "\n",
        "        # Event handlers\n",
        "        file_input.change(\n",
        "            fn=load_dataset,\n",
        "            inputs=[file_input],\n",
        "            outputs=[dataset_info, dataset_preview, features_choices, target_choices]\n",
        "        ).then(\n",
        "            fn=get_dataset_info,\n",
        "            outputs=[dataset_info]\n",
        "        ).then(\n",
        "            fn=lambda choices: (gr.Dropdown(choices=choices), gr.Dropdown(choices=choices)),\n",
        "            inputs=[features_choices],\n",
        "            outputs=[features_dropdown, target_dropdown]\n",
        "        )\n",
        "\n",
        "        train_button.click(\n",
        "            fn=train_model,\n",
        "            inputs=[features_dropdown, target_dropdown, model_dropdown, test_size_slider],\n",
        "            outputs=[training_output, training_status]\n",
        "        )\n",
        "\n",
        "        confusion_btn.click(\n",
        "            fn=create_confusion_matrix,\n",
        "            outputs=[viz_output]\n",
        "        )\n",
        "\n",
        "        importance_btn.click(\n",
        "            fn=create_feature_importance,\n",
        "            outputs=[viz_output]\n",
        "        )\n",
        "\n",
        "        performance_btn.click(\n",
        "            fn=create_model_performance,\n",
        "            outputs=[viz_output]\n",
        "        )\n",
        "\n",
        "        distribution_btn.click(\n",
        "            fn=create_data_distribution,\n",
        "            outputs=[viz_output]\n",
        "        )\n",
        "\n",
        "    return demo\n",
        "\n",
        "# Launch the interface\n",
        "if __name__ == \"__main__\":\n",
        "    demo = create_interface()\n",
        "    demo.launch(\n",
        "        share=True,\n",
        "        debug=True,\n",
        "        server_name=\"0.0.0.0\",\n",
        "        height=800\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 914
        },
        "id": "I9ChV8DnPbjW",
        "outputId": "f3ab3049-9116-49c5-f337-8e9e00a88cec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://fa4267ff35188401b2.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://fa4267ff35188401b2.gradio.live\" width=\"100%\" height=\"800\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}
